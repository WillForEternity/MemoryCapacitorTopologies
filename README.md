# Memcapacitive Reservoir Topologies

This project is a framework for creating and testing memcapacitor-based neuromorphic computing models.

## Project Structure

- `models/`              – core device models (e.g., `Memcapacitor`).
- `networks/`            – reservoir logic and topologies.
  - `networks/topologies/`   – each topology in its own file (`small_world.py`, …).
  - `networks/reservoir.py`  – `MemcapacitiveReservoir` implementation.
- `datasets/`            – loaders; one sub-folder per dataset (`mackey_glass/`, `lorenz/`, …).
- `tests/`               – verbose behavioural tests that print natural-language PASS/FAIL and save figures.
- `outputs/`       – images generated by the tests.
- `outputs/`             – future training logs, checkpoints, etc.
- `configs/`             – YAML/JSON experiment configs (planned).
- `experiments/`         – grid-search drivers (e.g. `grid_search_mackey_glass.py`, `grid_search_lorenz.py`).
- `training/`            – training pipeline (`training/train.py`) used by the experiment scripts.
- `venv/`                – optional local Python virtual environment.

## Design Philosophy: Human *and* AI Readability

This project is written so that **any human researcher or AI agent** can reason
about the codebase with minimal context switching.

* **Verbose, natural-language tests** – Every behaviour test (e.g. for
  `Memcapacitor`, dataset loaders, topology generators) prints explanatory
  PASS/FAIL commentary instead of opaque assertions.  This lets agents judge
  correctness directly from stdout and saved plots.
* **Self-documenting modules** – Each folder is strictly single-responsibility
  (`models/`, `datasets/`, `networks/…`).  Import paths are consistent and
  enumerated in the API table below.
* **Plug-and-play extensibility** – New topologies or datasets are discovered
  automatically by simple file placement and decorators, no central registry
  edit required.
* **Clear naming & typing** – Functions and variables use descriptive names and
  type hints so static analysers and LLMs can infer intent.


## API Quick Reference

> All paths assume your working directory is the project root (added to `PYTHONPATH`).

| Purpose | Import statement | Primary callables |
|---------|------------------|-------------------|
| Core device model | `from models.memcapacitor import Memcapacitor` | `Memcapacitor.forward(v)` , `Memcapacitor.reset()` |
| Generate a topology | `from networks.topologies import make_topology` | `make_topology("small_world", n_nodes=500, k=6, beta=0.2)` |
| Build a reservoir | `from networks.reservoir import MemcapacitiveReservoir` | `reservoir = MemcapacitiveReservoir(adj_matrix, input_dim)` |
| Load Mackey–Glass dataset | `from datasets import load_dataset` | `train, test = load_dataset("mackey_glass", length=10000)` |
| Run device-level verbose test | `python tests/test_memcapacitor_verbose.py` | PASS/FAIL + plots |
| Run topology verbose test | `python tests/test_topology_small_world_verbose.py` | PASS/FAIL + heat-map |
| Run dataset verbose test | `python tests/test_dataset_mackey_glass_verbose.py` | PASS/FAIL + plot |
| Run reservoir verbose test | `python tests/test_reservoir_forward_verbose.py` | PASS/FAIL + plot |
| Training pipeline (numeric) | `from training.train import run` | `metrics = run(cfg)` / `python -m training.train --config cfg.yaml` |
| Training + figure | `python -m training.train --config cfg.yaml --plot` | Saves coloured prediction PNG to `outputs/` |
| Train & evaluate | `from training.train import run` | `metrics = run(cfg_dict)` or `python -m training.train --config my.yaml` |

Add your own topology: create `networks/topologies/your_topology.py` containing a function decorated with `@register("your_name")` that returns an `(N, N)` `numpy.ndarray` adjacency. It will auto-register.

Add your own dataset: create `datasets/your_dataset/` with `generator.py` (or similar) exposing `load()` and a minimal `__init__.py` that re-exports `load`.

---

## Lorenz Attractor Example

The framework supports multi-dimensional chaotic time-series.  The new
`datasets/lorenz/` subpackage generates a 3-D Lorenz trajectory.

Quick sweep and model export:
```bash
python experiments/grid_search_lorenz.py \
    --sizes 100 200 \
    --lams 1e-3 1e-4 0 \
    --scales 0.5 1 2 \
    --srs 0.7 0.9 1.1 \
    --seeds 0 1 2 \
    --val_ratio 0.2 \
    --save_best best_lorenz.npz \
    --plot
```
This prints mean ± σ for validation/test MSE and saves the winning network
(adjacent matrix, `Win`, `W_out`, and full config) to `best_lorenz.npz` for
instant regeneration:
```python
import numpy as np, torch, pickle
npz = np.load("best_lorenz.npz", allow_pickle=True)
W, Win, W_out = map(torch.tensor, (npz["adjacency"], npz["Win"], npz["W_out"]))
config = eval(npz["config"].item())  # or use json/pickle for safer loading
```

---

## Verbose & Visual Outputs

`training.train.run` emits rich diagnostics:

* **Coordinate pairs** – For datasets that implement `datasets/<name>/reporting.py` with `verbose_pairs`, the pipeline prints `(ground-truth, predicted)` every *pair_stride* samples (default 2).
* **Figure (optional)** – Pass `plot: true` in the config or `--plot` on the CLI to save a Jet-colormap scatter of predictions vs. time to `output_dir` (default `outputs`).
  *The file is named `<dataset>_predictions_jet.png`; for the Lorenz example this is `outputs/lorenz_predictions_jet.png`.*
  The x-axis is sample index, the y-axis is the first dimension of the predicted vector, and the colour encodes amplitude so multi-dimensional behaviour is still visible.

Config keys of interest:
```yaml
verbose: true        # enable dataset‐specific textual output (default)
pair_stride: 2       # sampling stride for coordinate pairs
plot: false          # save prediction figure when true
output_dir: outputs
```

---

## Reproducibility & Scientific Best-Practices

This repository follows these guidelines:

1. **Deterministic seeds** – all calls that involve randomness accept a `random_seed` and default to a fixed value; experiment scripts expose this via CLI.
2. **Explicit device placement** – tensors are placed on the correct device (`cuda`/`cpu`) at creation time to avoid implicit transfers.
3. **Separation of concerns** – data generation, model definition, training, and evaluation are in distinct modules.
4. **Version-controlled results** – grid-search scripts can save the full winning network (`npz`) and prediction figures which are small enough to commit.
5. **Verbose logging** – tests and training print natural-language commentary so a human (or LLM) can audit results quickly.

See `tests/` and the example commands above for end-to-end, reproducible runs.

---

## Getting Started

1.  **Set up the virtual environment:**
    ```bash
    python3 -m venv venv
    source venv/bin/activate
    ```

2.  **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

3.  **Run tests:**
    ```bash
    # run all verbose tests
    python tests/test_memcapacitor_verbose.py
    python tests/test_topology_small_world_verbose.py
    python tests/test_dataset_mackey_glass_verbose.py
    python tests/test_reservoir_forward_verbose.py
    ```
